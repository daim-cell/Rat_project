# Rat_project

Explainable AI has been the field involved in explaining the results from machine learning models. Not only focusing on the accuracy of the models but also the rationale behind the answers. 
In accordance to this, researchers from Swansea university, UK and university of Utah, US collaborated to come up with a model that achieves similar accuracies compared to traditional models using probabilistic inferences. 
Here we implement their approach in python on a dataset from Kaggle called stroke prediction dataset. 
We also implemented a probabilistic model of neural nets to explain its result using the above-mentioned approach. 
This was all done in accordance to research aptitude test set up by CureMD (CureMD, n.d.). 

Original Paper link: https://arxiv.org/abs/2005.02074#:~:text=Explainable%20AI%20for%20Classification%20using%20Probabilistic%20Logic%20Inference,-Xiuyi%20Fan%2C%20Siyuan&text=Our%20method%20works%20by%20first,Knowledge%20Base%20with%20linear%20programming.
